{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SJpMzrXIWCitGPg8f4S72GqYZle_yW0x",
      "authorship_tag": "ABX9TyMBz0HnYPr5+gRfzUrOvMQb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saigo24/Dimplomado_Ciencia_Datos/blob/main/tarea6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "zGFRf6JUbO8d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redes Generativas Adversarias"
      ],
      "metadata": {
        "id": "5HcBWlmJfJt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el generador\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, img_shape),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), -1)\n",
        "        return img\n",
        "\n",
        "# Definir el discriminador\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(img_shape, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n",
        "\n",
        "# Configuración\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "latent_dim = 100\n",
        "img_shape = 28 * 28\n",
        "\n",
        "# Crear generador y discriminador\n",
        "generator = Generator(latent_dim, img_shape).to(device)\n",
        "discriminator = Discriminator(img_shape).to(device)\n",
        "\n",
        "# Función de pérdida y optimizadores\n",
        "adversarial_loss = nn.BCELoss()\n",
        "generator_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Cargar datos de entrenamiento (por ejemplo, MNIST)\n",
        "dataset = MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Entrenamiento\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        batch_size = imgs.shape[0]\n",
        "\n",
        "        # Preparar datos reales y datos de ruido\n",
        "        real_imgs = imgs.view(batch_size, -1).to(device)\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "\n",
        "        # Entrenar el discriminador\n",
        "        discriminator_optimizer.zero_grad()\n",
        "\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        real_output = discriminator(real_imgs)\n",
        "        real_loss = adversarial_loss(real_output, real_labels)\n",
        "\n",
        "        fake_imgs = generator(z)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        fake_output = discriminator(fake_imgs.detach())\n",
        "        fake_loss = adversarial_loss(fake_output, fake_labels)\n",
        "\n",
        "        discriminator_loss = (real_loss + fake_loss) / 2\n",
        "        discriminator_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "\n",
        "        # Entrenar el generador\n",
        "        generator_optimizer.zero_grad()\n",
        "\n",
        "        fake_output = discriminator(fake_imgs)\n",
        "        generator_loss = adversarial_loss(fake_output, real_labels)\n",
        "        generator_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "\n",
        "        # Mostrar progreso del entrenamiento\n",
        "        if (i+1) % 200 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], \"\n",
        "                  f\"Discriminator Loss: {discriminator_loss.item():.4f}, \"\n",
        "                  f\"Generator Loss: {generator_loss.item():.4f}\")\n",
        "\n",
        "    # Guardar imágenes generadas durante el entrenamiento\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(64, latent_dim).to(device)\n",
        "            generated_imgs = generator(z).reshape(-1, 1, 28, 28)\n",
        "            save_image(generated_imgs, f\"generated_images_epoch{epoch+1}.png\", nrow=8, normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im7w0t0cfFjK",
        "outputId": "d0d8108f-125d-483d-f0a3-93e6fd60dba5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [200/938], Discriminator Loss: 0.5444, Generator Loss: 1.7075\n",
            "Epoch [1/10], Step [400/938], Discriminator Loss: 0.5134, Generator Loss: 2.0192\n",
            "Epoch [1/10], Step [600/938], Discriminator Loss: 0.4230, Generator Loss: 3.3124\n",
            "Epoch [1/10], Step [800/938], Discriminator Loss: 0.4837, Generator Loss: 4.4507\n",
            "Epoch [2/10], Step [200/938], Discriminator Loss: 0.4607, Generator Loss: 2.6317\n",
            "Epoch [2/10], Step [400/938], Discriminator Loss: 0.4240, Generator Loss: 3.1243\n",
            "Epoch [2/10], Step [600/938], Discriminator Loss: 0.4681, Generator Loss: 2.9704\n",
            "Epoch [2/10], Step [800/938], Discriminator Loss: 0.4054, Generator Loss: 3.1892\n",
            "Epoch [3/10], Step [200/938], Discriminator Loss: 0.4419, Generator Loss: 2.2824\n",
            "Epoch [3/10], Step [400/938], Discriminator Loss: 0.4315, Generator Loss: 2.6357\n",
            "Epoch [3/10], Step [600/938], Discriminator Loss: 0.4512, Generator Loss: 2.3430\n",
            "Epoch [3/10], Step [800/938], Discriminator Loss: 0.4169, Generator Loss: 2.2408\n",
            "Epoch [4/10], Step [200/938], Discriminator Loss: 0.3980, Generator Loss: 2.1402\n",
            "Epoch [4/10], Step [400/938], Discriminator Loss: 0.5583, Generator Loss: 1.6001\n",
            "Epoch [4/10], Step [600/938], Discriminator Loss: 0.5113, Generator Loss: 1.5466\n",
            "Epoch [4/10], Step [800/938], Discriminator Loss: 0.5831, Generator Loss: 1.7151\n",
            "Epoch [5/10], Step [200/938], Discriminator Loss: 0.4710, Generator Loss: 1.6258\n",
            "Epoch [5/10], Step [400/938], Discriminator Loss: 0.4075, Generator Loss: 1.8283\n",
            "Epoch [5/10], Step [600/938], Discriminator Loss: 0.3670, Generator Loss: 1.6329\n",
            "Epoch [5/10], Step [800/938], Discriminator Loss: 0.4014, Generator Loss: 2.0002\n",
            "Epoch [6/10], Step [200/938], Discriminator Loss: 0.4194, Generator Loss: 2.4204\n",
            "Epoch [6/10], Step [400/938], Discriminator Loss: 0.4293, Generator Loss: 2.6849\n",
            "Epoch [6/10], Step [600/938], Discriminator Loss: 0.4282, Generator Loss: 2.5232\n",
            "Epoch [6/10], Step [800/938], Discriminator Loss: 0.4929, Generator Loss: 2.3146\n",
            "Epoch [7/10], Step [200/938], Discriminator Loss: 0.4740, Generator Loss: 1.8516\n",
            "Epoch [7/10], Step [400/938], Discriminator Loss: 0.4266, Generator Loss: 2.6860\n",
            "Epoch [7/10], Step [600/938], Discriminator Loss: 0.4833, Generator Loss: 1.2200\n",
            "Epoch [7/10], Step [800/938], Discriminator Loss: 0.4716, Generator Loss: 2.4916\n",
            "Epoch [8/10], Step [200/938], Discriminator Loss: 0.3919, Generator Loss: 3.0299\n",
            "Epoch [8/10], Step [400/938], Discriminator Loss: 0.4616, Generator Loss: 2.0678\n",
            "Epoch [8/10], Step [600/938], Discriminator Loss: 0.5164, Generator Loss: 2.8937\n",
            "Epoch [8/10], Step [800/938], Discriminator Loss: 0.3337, Generator Loss: 1.9229\n",
            "Epoch [9/10], Step [200/938], Discriminator Loss: 0.3391, Generator Loss: 1.7285\n",
            "Epoch [9/10], Step [400/938], Discriminator Loss: 0.4511, Generator Loss: 1.3354\n",
            "Epoch [9/10], Step [600/938], Discriminator Loss: 0.3860, Generator Loss: 2.4748\n",
            "Epoch [9/10], Step [800/938], Discriminator Loss: 0.4074, Generator Loss: 2.1612\n",
            "Epoch [10/10], Step [200/938], Discriminator Loss: 0.4359, Generator Loss: 3.0317\n",
            "Epoch [10/10], Step [400/938], Discriminator Loss: 0.3503, Generator Loss: 2.5974\n",
            "Epoch [10/10], Step [600/938], Discriminator Loss: 0.3255, Generator Loss: 2.1945\n",
            "Epoch [10/10], Step [800/938], Discriminator Loss: 0.3323, Generator Loss: 1.7207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generación de Rostros Artificiales usando DCGAN's"
      ],
      "metadata": {
        "id": "S3_UcV-khNWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Se usa una semilla para reproductibilidad\n",
        "manualSeed = 999\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpYhFImMhUdm",
        "outputId": "792d3951-d13f-4075-921b-bd5070ae9d40"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f36fa8b5150>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio del Dataset\n",
        "dataroot = \"/mnt/storage/Datasets/\"\n",
        "\n",
        "# Número de workers en el dataloader\n",
        "workers = 2\n",
        "\n",
        "# tamaño del lote\n",
        "batch_size = 128\n",
        "\n",
        "# tamaño base de las imágenes a la entrada\n",
        "image_size = 64\n",
        "\n",
        "# número de canales de entrenamiento\n",
        "nc = 3\n",
        "\n",
        "# tamaño delv ector latente\n",
        "nz = 100\n",
        "\n",
        "# tamaño de los mapas de características en el generador\n",
        "ngf = 64\n",
        "\n",
        "# tamaño de los mapas de características en el discriminador\n",
        "ndf = 64\n",
        "\n",
        "# Números de epocas\n",
        "num_epochs = 10\n",
        "\n",
        "# rata de aprendizaje\n",
        "lr = 0.0002\n",
        "\n",
        "# hiperparámetro Beta1 para el optimizador\n",
        "beta1 = 0.5\n",
        "\n",
        "# Número de GPUs, si no hay poner 0\n",
        "ngpu = 1"
      ],
      "metadata": {
        "id": "csiX0Bl3hbam"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ])"
      ],
      "metadata": {
        "id": "O1xPuttshdJh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el dataset\n",
        "dataset = datasets.ImageFolder(root=dataroot+'celeba',\n",
        "                           transform=transform)\n",
        "# Creamos el dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "# Decidimos en dónde se hará el entrenamiento\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# graficamos algunas de sus imágenes\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "JH2qFlbPhf5z",
        "outputId": "73915f65-1e00-44a2-c642-085cfa0a6bf3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-952864b8e6fa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creamos el dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m dataset = datasets.ImageFolder(root=dataroot+'celeba',\n\u001b[0m\u001b[1;32m      3\u001b[0m                            transform=transform)\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Creamos el dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/storage/Datasets/celeba'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inicialización de pesos para el discriminador y el generador\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "4lmld5D5nEu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Code\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # Se entra el vector de ruido a la primera convolución transpuesta\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # tamaño actual. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # tamaño actual. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # tamaño actual. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # tamaño actual. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # tamaño actual. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "aCnRJwPmnb0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creamos el generador\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# para uso de múltiples GPUs\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# aplicamos la aleatorización de pesos incializados\n",
        "netG.apply(weights_init)\n",
        "\n",
        "print(netG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "HSQwkEPpneuq",
        "outputId": "5423bb29-1933-4bd8-beca-3580c787cb4e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-12e38408306e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creamos el generador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnetG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# para uso de múltiples GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Generator.__init__() missing 1 required positional argument: 'img_shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # entrada es una imagen (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # tamaño actual. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # tamaño actual. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # tamaño actual. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # tamaño actual. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "RVedwSOKngta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el discriminador\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# para uso de múltiples GPUs\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# aplicamos la aleatorización de pesos incializados\n",
        "netD.apply(weights_init)\n",
        "\n",
        "print(netD)"
      ],
      "metadata": {
        "id": "xyoDDvSZnlj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perdida de entropía cruzada binaria\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# hacemos un lote de vectores aleatorios para visualizar\n",
        "#  el proceso de mejora del generador\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "#definimos las etiquetas de \"falso\" y \"verdadero\"\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# definimos los optimizadores de G y D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "AKHyjPDKnnqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "# listas para seguir el progreso\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# para cada epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # Para cada lote en el epoch\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Actualizamos la red D\n",
        "        ###########################\n",
        "        ## entrenamiento con las imágenes reales\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "        # pasamos el lote de imágenes reales al discriminador\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # perdida del lote real\n",
        "        errD_real = criterion(output, label)\n",
        "        # backpropagation\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## entrenamiento con las imágenes falsas\n",
        "        # Generamos lote de vectores aleatorios\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # Generamos imágenes falsas con G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Aplicamos clasificación de estos lotes falsos\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # perdida del lote falso\n",
        "        errD_fake = criterion(output, label)\n",
        "        # calculamos los gradientes de este lote, acumulado con el anterior\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # computamos la perdida total de D como la suma de perdidas\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Actualizamos la red G\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "        # al haber actualizado D, se hace otro paso con datos falsos usando el discriminador\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculamos la perdida del generador con base en que tan buena fue su capacidad de burlar a D\n",
        "        errG = criterion(output, label)\n",
        "        # Calculamos Gradientes\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # actualizamos G\n",
        "        optimizerG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # hacemos unas generaciones parciales para ver el desempeño de G\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "vDI509MLnpgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ipv8WA0nxeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# graficamos imágenes reales\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# graficamos las imágenes falsas del último epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dqOuy_wfnyOh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}